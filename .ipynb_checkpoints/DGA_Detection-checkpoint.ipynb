{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "r = 'D:\\LABs\\Diploma'\n",
    "os.chdir(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first CSV file, skipping the first column\n",
    "legit_1 = pd.read_csv('top-1m_0.csv', header=None, names=['domain'], usecols=[1])\n",
    "\n",
    "# Read the second CSV file\n",
    "legit_2 = pd.read_csv('top-1m_1.csv', header=None, names=['domain'])\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "result = pd.concat([legit_1, legit_2])\n",
    "\n",
    "legit = result.drop_duplicates(subset='domain')\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "result.to_csv('top-1m.csv', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\AppData\\Local\\Temp\\ipykernel_18096\\366226314.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  legit.loc[:, 'primary'] = [tldextract.extract(d).domain for d in legit['domain']]\n",
      "C:\\Users\\Mark\\AppData\\Local\\Temp\\ipykernel_18096\\366226314.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  legit.loc[:, 'tld'] = [tldextract.extract(d).suffix.split('.')[0] for d in legit['domain']]\n",
      "C:\\Users\\Mark\\AppData\\Local\\Temp\\ipykernel_18096\\366226314.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  legit['label'] = 'legit'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>primary</th>\n",
       "      <th>tld</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google.com</td>\n",
       "      <td>google</td>\n",
       "      <td>com</td>\n",
       "      <td>legit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook.com</td>\n",
       "      <td>facebook</td>\n",
       "      <td>com</td>\n",
       "      <td>legit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a-msedge.net</td>\n",
       "      <td>a-msedge</td>\n",
       "      <td>net</td>\n",
       "      <td>legit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazonaws.com</td>\n",
       "      <td>amazonaws</td>\n",
       "      <td>com</td>\n",
       "      <td>legit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft.com</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>com</td>\n",
       "      <td>legit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          domain    primary  tld  label\n",
       "0     google.com     google  com  legit\n",
       "1   facebook.com   facebook  com  legit\n",
       "2   a-msedge.net   a-msedge  net  legit\n",
       "3  amazonaws.com  amazonaws  com  legit\n",
       "4  microsoft.com  microsoft  com  legit"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tldextract\n",
    "\n",
    "legit.loc[:, 'primary'] = [tldextract.extract(d).domain for d in legit['domain']]\n",
    "legit.loc[:, 'tld'] = [tldextract.extract(d).suffix.split('.')[0] for d in legit['domain']]\n",
    "\n",
    "legit.columns = [['domain','primary','tld']]\n",
    "legit['label'] = 'legit'\n",
    "legit.to_csv('legit.csv', header=False, index=False)\n",
    "legit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tjdiesasrmmg.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ulcejbpxfpyt.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ukfscibfggjh.biz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vmeohqqktjvu.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vyimpnqeusnm.org</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             domain\n",
       "0  tjdiesasrmmg.com\n",
       "1  ulcejbpxfpyt.net\n",
       "2  ukfscibfggjh.biz\n",
       "3   vmeohqqktjvu.ru\n",
       "4  vyimpnqeusnm.org"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "dga = pd.read_csv('dga-feed-high.csv', header=None, comment=\"#\", dtype=str, names=['domain', 'description', 'date', 'url'])\n",
    "\n",
    "dga = dga[['domain']]\n",
    "\n",
    "# Display the first few rows of the modified DataFrame\n",
    "dga.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>primary</th>\n",
       "      <th>tld</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tjdiesasrmmg.com</td>\n",
       "      <td>tjdiesasrmmg</td>\n",
       "      <td>com</td>\n",
       "      <td>dga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ulcejbpxfpyt.net</td>\n",
       "      <td>ulcejbpxfpyt</td>\n",
       "      <td>net</td>\n",
       "      <td>dga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ukfscibfggjh.biz</td>\n",
       "      <td>ukfscibfggjh</td>\n",
       "      <td>biz</td>\n",
       "      <td>dga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vmeohqqktjvu.ru</td>\n",
       "      <td>vmeohqqktjvu</td>\n",
       "      <td>ru</td>\n",
       "      <td>dga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vyimpnqeusnm.org</td>\n",
       "      <td>vyimpnqeusnm</td>\n",
       "      <td>org</td>\n",
       "      <td>dga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             domain       primary  tld label\n",
       "0  tjdiesasrmmg.com  tjdiesasrmmg  com   dga\n",
       "1  ulcejbpxfpyt.net  ulcejbpxfpyt  net   dga\n",
       "2  ukfscibfggjh.biz  ukfscibfggjh  biz   dga\n",
       "3   vmeohqqktjvu.ru  vmeohqqktjvu   ru   dga\n",
       "4  vyimpnqeusnm.org  vyimpnqeusnm  org   dga"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dga.loc[:, 'primary'] = [tldextract.extract(d).domain for d in dga['domain']]\n",
    "dga.loc[:, 'tld'] = [tldextract.extract(d).suffix.split('.')[0] for d in dga['domain']]\n",
    "\n",
    "dga.columns = [['domain','primary','tld']]\n",
    "dga['label'] = 'dga'\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "dga.to_csv('dga.csv', header=False, index=False)\n",
    "\n",
    "dga.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>primary</th>\n",
       "      <th>tld</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conagra.net</td>\n",
       "      <td>conagra</td>\n",
       "      <td>net</td>\n",
       "      <td>legit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yakult.co.id</td>\n",
       "      <td>yakult</td>\n",
       "      <td>co</td>\n",
       "      <td>legit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ttbbank.com</td>\n",
       "      <td>ttbbank</td>\n",
       "      <td>com</td>\n",
       "      <td>legit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4kjxz.cn</td>\n",
       "      <td>4kjxz</td>\n",
       "      <td>cn</td>\n",
       "      <td>legit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uhvthpudougru.bz</td>\n",
       "      <td>uhvthpudougru</td>\n",
       "      <td>bz</td>\n",
       "      <td>dga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             domain        primary  tld  label\n",
       "0       conagra.net        conagra  net  legit\n",
       "1      yakult.co.id         yakult   co  legit\n",
       "2       ttbbank.com        ttbbank  com  legit\n",
       "3          4kjxz.cn          4kjxz   cn  legit\n",
       "4  uhvthpudougru.bz  uhvthpudougru   bz    dga"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allDomains = pd.concat([legit, dga], ignore_index=True)\n",
    "allDomains = allDomains.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "allDomains.to_csv('allDomains.csv', header=False, index=False)\n",
    "\n",
    "X, y = allDomains['tld'], allDomains['label']\n",
    "allDomains.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>primary</th>\n",
       "      <th>tld</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conagra.net</td>\n",
       "      <td>conagra</td>\n",
       "      <td>net</td>\n",
       "      <td>legit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yakult.co.id</td>\n",
       "      <td>yakult</td>\n",
       "      <td>co</td>\n",
       "      <td>legit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ttbbank.com</td>\n",
       "      <td>ttbbank</td>\n",
       "      <td>com</td>\n",
       "      <td>legit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4kjxz.cn</td>\n",
       "      <td>4kjxz</td>\n",
       "      <td>cn</td>\n",
       "      <td>legit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uhvthpudougru.bz</td>\n",
       "      <td>uhvthpudougru</td>\n",
       "      <td>bz</td>\n",
       "      <td>dga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             domain        primary  tld  label\n",
       "0       conagra.net        conagra  net  legit\n",
       "1      yakult.co.id         yakult   co  legit\n",
       "2       ttbbank.com        ttbbank  com  legit\n",
       "3          4kjxz.cn          4kjxz   cn  legit\n",
       "4  uhvthpudougru.bz  uhvthpudougru   bz    dga"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_row(row):\n",
    "    domain_parts = row['domain'].split('.')\n",
    "    if len(domain_parts) >= 2:\n",
    "        row['primary'], row['tld'] = domain_parts[0], domain_parts[1]\n",
    "    else:\n",
    "        row['primary'], row['tld'] = '', ''\n",
    "    return row\n",
    "\n",
    "# Check for empty items in the 'tld' column and fix suffix presence\n",
    "empty_tld_rows = allDomains.apply(lambda x: process_row(x) if x['tld'] == '' or pd.isnull(x['tld']) else x, axis=1)\n",
    "\n",
    "# Output the rows with empty 'tld' column\n",
    "empty_tld_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bazar = empty_tld_rows\n",
    "\n",
    "bazar.to_csv('bazar.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label        primary\n",
      "0  legit        conagra\n",
      "1  legit         yakult\n",
      "2  legit        ttbbank\n",
      "3  legit          4kjxz\n",
      "4    dga  uhvthpudougru\n"
     ]
    }
   ],
   "source": [
    "dga_set = bazar[['label','primary']]\n",
    "\n",
    "print(dga_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\LABs\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import necessary resources\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Embedding, LSTM, Dense, Activation, Dropout\n",
    "import sklearn\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build LSTM RNN model\n",
    "def build_model(max_features, maxlen):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define LSTM RNN model training and testing function\n",
    "def run_model(dga_set, max_epoch=50, batch_size=128):\n",
    "    \n",
    "    # extract data and labels \n",
    "    data = dga_set.values.tolist()\n",
    "    X = [x[1] for x in data]\n",
    "    labels = [x[0] for x in data]\n",
    "\n",
    "    # generate a dictionary of valid characters\n",
    "    valid_chars = {x:idx+1 for idx, x in enumerate(set(''.join(X)))}\n",
    "    max_features = len(valid_chars) + 1\n",
    "    maxlen = np.max([len(x) for x in X])\n",
    "\n",
    "    # encode each domain\n",
    "    X = [[valid_chars[y] for y in x] for x in X]\n",
    "    X = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "\n",
    "    # convert labels to 0-1\n",
    "    y = [0 if x == 'legit' else 1 for x in labels]\n",
    "\n",
    "    final_data = []\n",
    "\n",
    "    # split data into training and test data\n",
    "    X_train, X_test, y_train, y_test, _, label_test = train_test_split(X, y, labels, \n",
    "                                                               test_size=0.2, random_state = 0)\n",
    "\n",
    "    model = build_model(max_features, maxlen)\n",
    "\n",
    "    # split training data again into training and validation data\n",
    "    X_train, X_holdout, y_train, y_holdout = train_test_split(X_train, y_train, test_size=0.05,random_state = 0)\n",
    "    best_iter = -1\n",
    "    best_auc = 0.0\n",
    "    out_data = {}\n",
    "\n",
    "    # saving weights for sudden train interruption\n",
    "    # if os.path.exists(checkpoint_path):\n",
    "    #     model.load_weights(checkpoint_path)\n",
    "    # elif os.path.exists(\"model_lstm.weights.h5\"):\n",
    "    #     model.load_weights(\"model_lstm.weights.h5\")\n",
    "    #     print(\"ok\")\n",
    "\n",
    "    for ep in range(max_epoch):\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "\n",
    "        model.fit(X_train, y_train, batch_size=batch_size, epochs=1)\n",
    "\n",
    "        t_probs = model.predict(X_holdout)[0]\n",
    "        t_auc = sklearn.metrics.roc_auc_score(y_holdout, t_probs)\n",
    "\n",
    "        print ('Epoch %d: auc = %f (best=%f)' % (ep, t_auc, best_auc))\n",
    "\n",
    "        if t_auc > best_auc:\n",
    "            best_auc = t_auc\n",
    "            best_iter = ep\n",
    "\n",
    "            probs = model.predict(X_test)\n",
    "\n",
    "            out_data = {'y':y_test, 'labels': label_test, 'probs':probs, 'epochs': ep,\n",
    "                            'confusion_matrix': sklearn.metrics.confusion_matrix(y_test, probs > .5)}\n",
    "            \n",
    "            print (\"confusion matrix on test data:\")\n",
    "            print (sklearn.metrics.confusion_matrix(y_test, probs > .5))\n",
    "        else:\n",
    "            # stop the process if performance has not improved for more than 2 epochs\n",
    "            if (ep-best_iter) > 2:\n",
    "                break\n",
    "\n",
    "        final_data.append(out_data)\n",
    "\n",
    "    return valid_chars, model, final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\LABs\\.venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\LABs\\.venv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\LABs\\.venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "11049/11049 [==============================] - 489s 44ms/step - loss: 0.1038\n",
      "2327/2327 [==============================] - 16s 7ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [74434, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# get predictions and performance of LSTM model on test data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m valid_chars, model_lstm, result_lstm \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdga_set\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 49\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(dga_set, max_epoch, batch_size)\u001b[0m\n\u001b[0;32m     46\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     48\u001b[0m t_probs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_holdout)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 49\u001b[0m t_auc \u001b[38;5;241m=\u001b[39m \u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_holdout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m: auc = \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m (best=\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (ep, t_auc, best_auc))\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t_auc \u001b[38;5;241m>\u001b[39m best_auc:\n",
      "File \u001b[1;32md:\\LABs\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32md:\\LABs\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:640\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    638\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[0;32m    639\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[0;32m    649\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[0;32m    650\u001b[0m         y_true,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    653\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    654\u001b[0m     )\n",
      "File \u001b[1;32md:\\LABs\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[1;32md:\\LABs\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:387\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m     )\n\u001b[1;32m--> 387\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m auc(fpr, tpr)\n",
      "File \u001b[1;32md:\\LABs\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32md:\\LABs\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1108\u001b[0m, in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1007\u001b[0m     {\n\u001b[0;32m   1008\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1017\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m ):\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m \n\u001b[0;32m   1021\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1108\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1112\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32md:\\LABs\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:819\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m--> 819\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[0;32m    821\u001b[0m y_score \u001b[38;5;241m=\u001b[39m column_or_1d(y_score)\n",
      "File \u001b[1;32md:\\LABs\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [74434, 1]"
     ]
    }
   ],
   "source": [
    "# get predictions and performance of LSTM model on test data\n",
    "valid_chars, model_lstm, result_lstm = run_model(dga_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the lstm model\n",
    "model_lstm.save('lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.save_weights(\"model_lstm.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary of valid characters in data set\n",
    "import pickle\n",
    "pkl_file = \"valid_chars.pkl\"  \n",
    "with open(pkl_file, 'wb') as file:  \n",
    "    pickle.dump(valid_chars, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
